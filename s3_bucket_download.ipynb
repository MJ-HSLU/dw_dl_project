{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook was provided by the lecturer as a way to backup files from our S3 bucket.\n",
    "This was just in case we would have reached our USD 100 limit in AWS and lose access to our data.\n",
    "The data for the project was processed by the lambda function (code: fetch_store_api_data_s3_and_database.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import boto3 # make --> pip install boto3\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T08:49:06.795569Z",
     "start_time": "2024-05-10T08:49:03.695762200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1131dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T08:49:39.552147200Z",
     "start_time": "2024-05-10T08:49:37.168441Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Accessing the S3 buckets using boto3 client\"\"\"\n",
    "s3_client =boto3.client('s3')\n",
    "s3_bucket_name='lakebucketv3'\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id='xxx',\n",
    "                    aws_secret_access_key='xxx',\n",
    "                    aws_session_token='xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Getting data files from the AWS S3 bucket as denoted above and printing the first 10 file names having prefix \"2019/7/8\" \"\"\"\n",
    "my_bucket=s3.Bucket(s3_bucket_name)\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.all():\n",
    "    print(my_bucket_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_directory = 'weather'\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.all():\n",
    "    # Key will be the full file path in S3, we split it to get the file name\n",
    "    file_name = my_bucket_object.key\n",
    "\n",
    "    # Construct the full local file path\n",
    "    local_file_path = os.path.join(local_directory, file_name)\n",
    "\n",
    "    # Make sure the directory exists, if not, create it\n",
    "    local_file_directory = os.path.dirname(local_file_path)\n",
    "    if not os.path.exists(local_file_directory):\n",
    "        os.makedirs(local_file_directory)\n",
    "\n",
    "    # Download the file\n",
    "    if '.json' in str(my_bucket_object.key):\n",
    "        print(f\"Downloading {file_name} to {local_file_path}...\")\n",
    "        my_bucket.download_file(my_bucket_object.key, local_file_path)\n",
    "    else:\n",
    "        print('skip_directory or file', my_bucket_object.key)\n",
    "\n",
    "print(\"All files have been downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2bb7b-5119-4818-8c94-b6125bd2d81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
